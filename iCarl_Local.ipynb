{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iCarl_Local.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubenIng93/OWR-ImageClassification/blob/main/iCarl_Local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akfcjGhzYoJI"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLlxxtJUicTg"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Subset, DataLoader, ConcatDataset, Dataset\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r652h451ijEB"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 70\n",
        "n_classes = 100"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lvtjd3-ilVd"
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./OWR_Tools'):\n",
        "  !git clone https://github.com/rubenIng93/OWR-ImageClassification\n",
        "  !mv 'OWR-ImageClassification' 'OWR_Tools'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKduHtA9PjZZ"
      },
      "source": [
        "# define the transformation\n",
        "train_transform = transforms.Compose(\n",
        "                    [transforms.RandomCrop(size = 32, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2009,  0.1984,  0.2023))]\n",
        "                    # normalized wrt the real cifar100 dataset\n",
        "                )\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "                    [transforms.ToTensor(),\n",
        "                     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "                    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2009,  0.1984,  0.2023))]\n",
        "                    # normalized wrt the real cifar100 dataset\n",
        "                )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa9_xrtoDvdz"
      },
      "source": [
        "from OWR_Tools.owr_dataset import Cifar100Dataset\n",
        "trainset = Cifar100Dataset(split='train', transform=train_transform, open_world=True)\n",
        "testset = Cifar100Dataset(split='test', transform=test_transform, open_world=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzP7St3YH3qe"
      },
      "source": [
        "from OWR_Tools.resnet import resnet32 as rn32\n",
        "from OWR_Tools.utils import *\n",
        "from OWR_Tools.cosine_resnet import resnet32 as cos_rn32\n",
        "from OWR_Tools.icarl import iCaRLTrainer\n",
        "from OWR_Tools.classifiers_study import CSEnvironment\n",
        "from OWR_Tools.losses_study import Loss_Experiments\n",
        "from OWR_Tools.open_world import Open_World\n",
        "from OWR_Tools.variation_v4 import Variations_Model\n",
        "resnet32 = cos_rn32().cuda()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZBFTm_rS8oF"
      },
      "source": [
        "# CLASSIFIER STUDY\n",
        "\n",
        "# instantiate the file writer\n",
        "file_writer = FileWriter(\"cosine_classifier_Adam.dat\")\n",
        "# create the train class\n",
        "cs_study = CSEnvironment(\n",
        "    [144],\n",
        "    file_writer,\n",
        "    trainset,\n",
        "    testset,\n",
        "    70, #epochs\n",
        "    resnet32,\n",
        "    10, # splits\n",
        "    batch_size,\n",
        "    'KNN'\n",
        "    )\n",
        "\n",
        "# run the training\n",
        "start = time.time()\n",
        "cs_study.run_loop()\n",
        "end = time.time()\n",
        "print(f\"Execution Time: {(end-start)/60} m\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azEzZZrme_oc"
      },
      "source": [
        "# VARIATION\n",
        "\n",
        "# instantiate the file writer\n",
        "file_writer = FileWriter(\"variation.dat\")\n",
        "# create the train class\n",
        "variation = Variations_Model(\n",
        "    [2],\n",
        "    file_writer,\n",
        "    trainset,\n",
        "    testset,\n",
        "    70, #epochs\n",
        "    resnet32,\n",
        "    10, # splits\n",
        "    batch_size    \n",
        "    )\n",
        "\n",
        "# run the training\n",
        "variation.run_loop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23rS85nr5i00"
      },
      "source": [
        "# LOSS STUDY\n",
        "\n",
        "# instantiate the file writer\n",
        "file_writer = FileWriter(\"l2_ce_accuracy.dat\")\n",
        "# create the train class\n",
        "losses = Loss_Experiments(\n",
        "    [145],\n",
        "    file_writer,\n",
        "    trainset,\n",
        "    testset,\n",
        "    70, #epochs\n",
        "    resnet32,\n",
        "    10, # splits\n",
        "    batch_size,\n",
        "    'ce', # classification loss\n",
        "    'l2' # distillation loss\n",
        "    )\n",
        "\n",
        "# run the training\n",
        "losses.run_loop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRdwCFoIbDB1"
      },
      "source": [
        "# BASELINES\n",
        "\n",
        "# instantiate the file writer\n",
        "file_writer = FileWriter(\"owr_cwr.dat\")\n",
        "# create the train class\n",
        "icarl = iCaRLTrainer(\n",
        "    [2],\n",
        "    file_writer,\n",
        "    trainset,\n",
        "    testset,\n",
        "    70, #epochs\n",
        "    resnet32,\n",
        "    5, # splits\n",
        "    batch_size,\n",
        "    )\n",
        "\n",
        "# run the training\n",
        "icarl.run_loop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fW6WElbBqb4"
      },
      "source": [
        "**Chart Scripts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx1kgRaQPxnM"
      },
      "source": [
        "# OPEN WORLD CHART\n",
        "\n",
        "data1 = unpickle('/content/OWR_Tools/result_files/open_world/harmonic_means_owr_144_var.pth')\n",
        "data2 = unpickle('/content/OWR_Tools/result_files/open_world/harmonic_means_owr_145_var.pth')\n",
        "data3 = unpickle('/content/OWR_Tools/result_files/open_world/harmonic_means_owr_2_var.pth')\n",
        "\n",
        "\n",
        "tr1 = []\n",
        "tr2 = []\n",
        "tr3 = []\n",
        "tr4 = []\n",
        "tr5 = []\n",
        "tr6 = []\n",
        "\n",
        "for d1, d2, d3 in zip(data1, data2, data3):\n",
        "  if isinstance(d1, dict):    \n",
        "    tr1.append((d1['0.5']+ d2['0.5']+ d3['0.5'])/3*100)\n",
        "    tr2.append((d1['0.6']+ d2['0.6']+ d3['0.6'])/3*100)\n",
        "    tr3.append((d1['0.7']+ d2['0.7']+ d3['0.7'])/3*100)\n",
        "    tr4.append((d1['0.8']+ d2['0.8']+ d3['0.8'])/3*100)\n",
        "    tr5.append((d1['0.9']+ d2['0.9']+ d3['0.9'])/3*100)\n",
        "    tr6.append((d1['0.95']+ d2['0.95']+ d3['0.95'])/3*100)\n",
        "\n",
        "print(tr1)\n",
        "\n",
        "\n",
        "plt.plot(range(1, 6), tr1, label='0.5', marker='.')\n",
        "plt.plot(range(1, 6), tr2, label='0.6', marker='.')\n",
        "plt.plot(range(1, 6), tr3, label='0.7', marker='.')\n",
        "plt.plot(range(1, 6), tr4, label='0.8', marker='.')\n",
        "plt.plot(range(1, 6), tr5, label='0.9', marker='.')\n",
        "plt.plot(range(1, 6), tr6, label='0.95', marker='.')\n",
        "plt.xlabel('split')\n",
        "plt.ylabel('Accuracy [%]')\n",
        "plt.suptitle('Harmonic mean between closed and open world')\n",
        "plt.title('for different threshold values - variation')\n",
        "plt.xticks([ 1, 2, 3, 4, 5])\n",
        "plt.yticks(range(20,70,10))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('open_world_h_means_var.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdJ6JuQIR8SF"
      },
      "source": [
        "# TREND SCRIPT\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import statistics\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "files_paths = [\n",
        "    '/content/OWR_Tools/result_files/icarl_adam_accuracies.dat',\n",
        "    '/content/OWR_Tools/result_files/lwf_accuracies.dat',\n",
        "    '/content/OWR_Tools/result_files/finetuning_accuracies.dat',\n",
        "    '/content/OWR_Tools/result_files/var_final_acc.dat'\n",
        "    ]\n",
        "\n",
        "\n",
        "labels = ['iCaRL', 'LwF', 'Finetuning', 'Our variation']\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "\n",
        "for i, data in enumerate(files_paths):\n",
        "\n",
        "    split_0, split_1, split_2, split_3, split_4 = [], [], [], [], []\n",
        "    split_5, split_6, split_7, split_8, split_9 = [], [], [], [], []\n",
        "\n",
        "    with open(data, 'r') as _file:\n",
        "        values = csv.reader(_file, delimiter='\\t')\n",
        "        header = True\n",
        "        for row in values:\n",
        "            if header:\n",
        "                header = False\n",
        "            else:\n",
        "                split_0.append(float(row[1])*100)\n",
        "                split_1.append(float(row[2])*100)\n",
        "                split_2.append(float(row[3])*100)\n",
        "                split_3.append(float(row[4])*100)\n",
        "                split_4.append(float(row[5])*100)\n",
        "                split_5.append(float(row[6])*100)\n",
        "                split_6.append(float(row[7])*100)\n",
        "                split_7.append(float(row[8])*100)\n",
        "                split_8.append(float(row[9])*100)\n",
        "                split_9.append(float(row[10])*100)\n",
        "\n",
        "    mean_values = []\n",
        "    stds = []\n",
        "    list_of_lists = [split_0, split_1, split_2, split_3,\n",
        "                    split_4, split_5, split_6, split_7, split_8, split_9]\n",
        "\n",
        "    for _list in list_of_lists:\n",
        "        mean_values.append(statistics.mean(_list))\n",
        "        stds.append(statistics.stdev(_list))\n",
        "\n",
        "    # 95% ci\n",
        "    ci = 1.96 * np.array(stds) / 3**(0.5)\n",
        "    #print(ci)\n",
        "    x = range(1,11)\n",
        "\n",
        "    means_np = np.array(mean_values)\n",
        "    print(means_np)\n",
        "    #ci_up = ci + means_np\n",
        "    #ci_low = means_np - ci\n",
        "    #ax.plot(x, mean_values, 'o-',label=labels[i])\n",
        "    ax.errorbar(x, mean_values, yerr=stds, label=labels[i], linewidth=2.2)\n",
        "    #ax.fill_between(x, ci_up, ci_low, alpha=0.2, label='95% ci')\n",
        "\n",
        "# Edit the layout\n",
        "\n",
        "ax.legend(prop={'size':15})\n",
        "ax.grid()\n",
        "ax.set_ylim(0,100)\n",
        "ax.set_yticks(range(0,101,10))\n",
        "ax.set_xticks(x)\n",
        "ax.set_title('Variation - comparison w.r.t. baselines ', fontsize=17)\n",
        "ax.set_xlabel('split', fontsize=15)\n",
        "ax.set_ylabel('Accuracy [%]', fontsize=15)\n",
        "\n",
        "fig.show()\n",
        "plt.savefig('variation_comparison.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSDp6GiEYpl6"
      },
      "source": [
        "# Variation graph\n",
        "\n",
        "new_calls = []\n",
        "old_calls = []\n",
        "new_acc = []\n",
        "old_acc = []\n",
        "\n",
        "with open('/content/OWR_Tools/result_files/var_nets.dat', 'r') as _file:\n",
        "    values = csv.reader(_file, delimiter='\\t')\n",
        "    header = True\n",
        "    count = 1\n",
        "    for row in values:\n",
        "        if header:\n",
        "          header = False\n",
        "        else:\n",
        "          if count == 1:\n",
        "            for split in range(1,10):\n",
        "              new_calls.append(float(row[split])*100)\n",
        "          elif count == 2:\n",
        "            for split in range(1,10):\n",
        "              old_calls.append(float(row[split])*100)\n",
        "          elif count == 3:\n",
        "            for split in range(1,10):\n",
        "              new_acc.append(float(row[split])*100)\n",
        "          elif count == 4:\n",
        "            for split in range(1,10):\n",
        "              old_acc.append(float(row[split])*100)\n",
        "          count += 1\n",
        "\n",
        "labels = [str(i) for i in range(2,11)]\n",
        "x = np.arange(len(new_acc))\n",
        "width = 0.20\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, new_calls, width, label='New predictions',\\\n",
        "                alpha=0.6, color='tab:olive')\n",
        "rects2 = ax.bar(x + width/2, old_calls, width, label='Old predictions', \\\n",
        "                alpha=0.6, color='tab:brown')\n",
        "\n",
        "ax.plot(x, new_acc, label='New accuracy', linewidth=2)\n",
        "ax.plot(x, old_acc, label='Old accuracy', linewidth=2)\n",
        "\n",
        "\n",
        "ax.set_ylabel('Percentace accuracy / calls')\n",
        "ax.set_xlabel('split')\n",
        "ax.set_title('Variation performances')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "ax.grid()\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.savefig('variation_aggregated.png')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}