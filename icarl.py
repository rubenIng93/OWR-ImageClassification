from tqdm import tqdm
from OWR_Tools.utils import *
from OWR_Tools.resnet import resnet32 as rn32
import numpy as np
from torch.backends import cudnn
import torch
import torch.nn as nn
from torch.utils.data import Subset, DataLoader
import torch.optim as optim
import copy
from sklearn.metrics import confusion_matrix


class iCaRLTrainer():

    def __init__(self, seeds, file_writer, trainset, testset,
                 epochs, net, splits, b_size, mode):
        '''
        Args:
        - seeds: the list of seeds, aimed to the external loop;
        - file_writer: the FileWriter class to collect the results;
        - trainset: the Training images preprocessed;
        - testset: the Testing images preprocessed;
        - epochs: the number of epochs
        - net: the model, in this case resnet32
        - splits: the number of splits in which the classes are divided
        - scheduler: the training scheduler
        - b_size: the size of batches
        - mode: 'finetuning', 'lwf' or 'icarl'
        '''

        self.seeds = seeds
        self.writer = file_writer
        self.trainset = trainset
        self.testset = testset
        self.epochs = epochs
        self.net = net
        self.splits = splits
        self.batch_size = b_size
        self.mode = mode
        self.map = {}
        self.exemplars_set = {}
        self.K = 2000

        # parameters generated by internal funcitons
        self.running_loss_history = []
        self.running_corrects_history = []
        self.accuracy_per_split = []
        self.criterion = ""
        self.train_dataloader = ""
        self.test_dataloader = ""
        self.optimizer = ""
        self.scheduler = ""
        self.all_targets = torch.tensor([])
        self.all_predictions = torch.tensor([])
        self.old_net = ""

        # Optimization of cuda resources
        cudnn.benchmark


    def train(self, split):

        self.map = self.trainset.map

        for e in range(self.epochs):

            # initialize the epoch's metrics
            running_loss = 0.0
            running_corrects = 0.0

            # iterate over the batches
            for inputs, labels in self.train_dataloader:

                # move to GPUs
                inputs = inputs.cuda()
                # print(labels)
                labels = map_label_2(self.map, labels)
                # map the label in range [split * 10, split + 10 * 10]
                # labels = map_label(labels, self.trainset.actual_classes, split)
                # transform it in one hot encoding to fit the BCELoss
                onehot_labels = torch.eye(split*10+10)[labels].to("cuda") # dimension [batchsize, classes]

                if split > 0:
                  # use the exemplars coming from the previous step
                  pass

    def distillation(self, new_onehot_labels, split):

        m = nn.Sigmoid()
        # extract the features using the old network for each exemplar set
        # and take the mean
        exemplars_means = {}

        for ex_set in self.exemplar_set.keys():
            # extract the features for each image
            loader = DataLoader(self.exemplar_set[ex_set], batch_size=len(self.exemplar_set[ex_set]))
            mean_ex = []
            for img in loader:
                img = img.cuda()
                img = self.old_net.extract_features(self)
                pass

                    

        
    def classify(self, net, mapped_inputs):

        means = {}
        # nearest means class classifier
        for label in self.exemplar_set.keys(): # requires mapping on labels ?
            label = self.trainset.map[label]
            loader = DataLoader(self.exemplar_set[label], batch_size=len(self.exemplar_set[label]))
            for img, target in loader: # a single batch
                img = img.cuda()
                target = target.cuda()
                net = net.cuda()
                features = net.extract_features(img)
                mean = torch.mean(features, 0) # this is the mean of all images in the same class exemplars
                means[label] = mean

        # assing the class to the inputs
        norms = torch.tensor([])
        for k in means.keys(): # are these labels ordered ?
            mean_k = means[k].cuda()
            torch.stack(
              (norms, torch.norm((net.extract_features(mapped_inputs) - mean_k), dim=0))
            )
        
        return torch.argmin(norms)

               
